{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f93527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 10:50:46.778115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745484647.417693   24040 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745484647.591635   24040 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745484649.138689   24040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745484649.138716   24040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745484649.138717   24040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745484649.138719   24040 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-24 10:50:49.305013: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "import re\n",
    "from langdetect import detect\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311dc6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading airbnb reviews dataset...\n",
      "Orginal dataset\n",
      "                  listing_id                   id        date  reviewer_id  \\\n",
      "0                    164448               407660  2011-07-30       870312   \n",
      "1                    164448               451097  2011-08-16       901633   \n",
      "2                    164448               472271  2011-08-24       894674   \n",
      "3                    164448               521708  2011-09-11       232485   \n",
      "4                    164448               568347  2011-09-26       896712   \n",
      "...                     ...                  ...         ...          ...   \n",
      "144943  1305729897949100039  1317299844322463966  2024-12-22    666963478   \n",
      "144944  1306393577432561110  1315873156254706149  2024-12-20    442177472   \n",
      "144945  1310885179474906446  1316587888366107935  2024-12-21     53058534   \n",
      "144946  1312171107579620356  1320280905319488958  2024-12-26    595482193   \n",
      "144947  1316786620019656619  1322401494741586698  2024-12-29    135251598   \n",
      "\n",
      "       reviewer_name                                           comments  \n",
      "0               Fred  great fun at lidia's. she had the power adapte...  \n",
      "1             Julien  Great centrally located room, very nice facili...  \n",
      "2            Liliana  Lidia is a very nice person. Very good plase t...  \n",
      "3               Ravi  Great host, although we were late in our arriv...  \n",
      "4               Ruud  Good location (for us), the bed was good and t...  \n",
      "...              ...                                                ...  \n",
      "144943        Jurgen  mooi appartement op de perfecte ligging in de ...  \n",
      "144944          Alex  Had a great stay at Jairo’s flat! The room its...  \n",
      "144945        Danish  Tunnelbanan går precis utanför, så det är enke...  \n",
      "144946       Abdulla  lägenheten är inte renoverad på väldigt lång t...  \n",
      "144947          Olle  Fantastisk värd, perfekt läge på boendet! Läge...  \n",
      "\n",
      "[144948 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "print(\"loading airbnb reviews dataset...\")\n",
    "df = pd.read_csv(\"reviews.csv\")\n",
    "print(f\"Orginal dataset\\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e85c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean html tags\n",
    "def clean_html(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r\"<.*?>\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac487225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remoing empty comments\n",
      "                  listing_id                   id        date  reviewer_id  \\\n",
      "0                    164448               407660  2011-07-30       870312   \n",
      "1                    164448               451097  2011-08-16       901633   \n",
      "2                    164448               472271  2011-08-24       894674   \n",
      "3                    164448               521708  2011-09-11       232485   \n",
      "4                    164448               568347  2011-09-26       896712   \n",
      "...                     ...                  ...         ...          ...   \n",
      "144943  1305729897949100039  1317299844322463966  2024-12-22    666963478   \n",
      "144944  1306393577432561110  1315873156254706149  2024-12-20    442177472   \n",
      "144945  1310885179474906446  1316587888366107935  2024-12-21     53058534   \n",
      "144946  1312171107579620356  1320280905319488958  2024-12-26    595482193   \n",
      "144947  1316786620019656619  1322401494741586698  2024-12-29    135251598   \n",
      "\n",
      "       reviewer_name                                           comments  \n",
      "0               Fred  great fun at lidia's. she had the power adapte...  \n",
      "1             Julien  Great centrally located room, very nice facili...  \n",
      "2            Liliana  Lidia is a very nice person. Very good plase t...  \n",
      "3               Ravi  Great host, although we were late in our arriv...  \n",
      "4               Ruud  Good location (for us), the bed was good and t...  \n",
      "...              ...                                                ...  \n",
      "144943        Jurgen  mooi appartement op de perfecte ligging in de ...  \n",
      "144944          Alex  Had a great stay at Jairo’s flat! The room its...  \n",
      "144945        Danish  Tunnelbanan går precis utanför, så det är enke...  \n",
      "144946       Abdulla  lägenheten är inte renoverad på väldigt lång t...  \n",
      "144947          Olle  Fantastisk värd, perfekt läge på boendet! Läge...  \n",
      "\n",
      "[144934 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove the empty comments rows\n",
    "df = df.dropna(subset=[\"comments\"])\n",
    "df[\"comments\"] = df[\"comments\"].apply(clean_html)\n",
    "print(f\"After remoing empty comments\\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76802794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the rows that isn't in English\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "df[\"is_english\"] = df[\"comments\"].apply(is_english)\n",
    "df = df[df[\"is_english\"]]\n",
    "print(f\"After removing non-english comments\\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40565f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained BERT model for sentiment analysis...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pre-trained BERT model for sentiment analysis...\")\n",
    "# load a pre-trained bert model from tensorflow hub\n",
    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76be1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"   # forces CPU-only\n",
    "\n",
    "\n",
    "def build_classifier_model():\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        hub_layer = hub.KerasLayer(model_url, trainable=False)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        hub_layer,\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labels for training model...\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "print(\"Creating labels for training model...\")\n",
    "positive_words = ['great', 'good', 'nice', 'excellent', 'perfect', 'happy', 'wonderful', \n",
    "                 'fantastic', 'amazing', 'love', 'best', 'beautiful', 'clean', 'comfortable']\n",
    "negative_words = ['bad', 'poor', 'terrible', 'horrible', 'awful', 'worst', 'dirty', \n",
    "                 'disappointing', 'disappointment', 'uncomfortable', 'problem', 'not clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sentiment(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 1\n",
    "    \n",
    "    text = text.lower()\n",
    "    pos_count = sum(1 for word in positive_words if word in text)\n",
    "    neg_count = sum(1 for word in negative_words if word in text)\n",
    "\n",
    "    if neg_count > pos_count:\n",
    "        return 0 # negative\n",
    "    else:\n",
    "        return 1 # Default to positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple labels\n",
    "df[\"sentiment_label\"] = df[\"comments\"].apply(simple_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample subset for training\n",
    "sample_size = min(10000, len(df))\n",
    "sample_df = df.sample(sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ef2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation sets\n",
    "train_text, val_text, train_labels, val_labels = train_test_split(\n",
    "    sample_df[\"comments\"].values,\n",
    "    sample_df[\"sentiment_label\"].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab262a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create and train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_classifier_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      4\u001b[0m     x\u001b[38;5;241m=\u001b[39mtrain_text,\n\u001b[1;32m      5\u001b[0m     y\u001b[38;5;241m=\u001b[39mtrain_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mbuild_classifier_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_classifier_model\u001b[39m():\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      8\u001b[0m         hub_layer \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(model_url, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m     model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     11\u001b[0m         hub_layer,\n\u001b[1;32m     12\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     13\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     14\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# create and train the model\n",
    "model = build_classifier_model()\n",
    "history = model.fit(\n",
    "    x=train_text,\n",
    "    y=train_labels,\n",
    "    validation_data=(val_text, val_labels),\n",
    "    epochs=5,\n",
    "    batch_size=8,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
