{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f93527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "import re\n",
    "from langdetect import detect\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311dc6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading airbnb reviews dataset...\n",
      "Orginal dataset\n",
      "                  listing_id                   id        date  reviewer_id  \\\n",
      "0                    164448               407660  2011-07-30       870312   \n",
      "1                    164448               451097  2011-08-16       901633   \n",
      "2                    164448               472271  2011-08-24       894674   \n",
      "3                    164448               521708  2011-09-11       232485   \n",
      "4                    164448               568347  2011-09-26       896712   \n",
      "...                     ...                  ...         ...          ...   \n",
      "144943  1305729897949100039  1317299844322463966  2024-12-22    666963478   \n",
      "144944  1306393577432561110  1315873156254706149  2024-12-20    442177472   \n",
      "144945  1310885179474906446  1316587888366107935  2024-12-21     53058534   \n",
      "144946  1312171107579620356  1320280905319488958  2024-12-26    595482193   \n",
      "144947  1316786620019656619  1322401494741586698  2024-12-29    135251598   \n",
      "\n",
      "       reviewer_name                                           comments  \n",
      "0               Fred  great fun at lidia's. she had the power adapte...  \n",
      "1             Julien  Great centrally located room, very nice facili...  \n",
      "2            Liliana  Lidia is a very nice person. Very good plase t...  \n",
      "3               Ravi  Great host, although we were late in our arriv...  \n",
      "4               Ruud  Good location (for us), the bed was good and t...  \n",
      "...              ...                                                ...  \n",
      "144943        Jurgen  mooi appartement op de perfecte ligging in de ...  \n",
      "144944          Alex  Had a great stay at Jairo’s flat! The room its...  \n",
      "144945        Danish  Tunnelbanan går precis utanför, så det är enke...  \n",
      "144946       Abdulla  lägenheten är inte renoverad på väldigt lång t...  \n",
      "144947          Olle  Fantastisk värd, perfekt läge på boendet! Läge...  \n",
      "\n",
      "[144948 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "print(\"loading airbnb reviews dataset...\")\n",
    "df = pd.read_csv(\"reviews.csv\")\n",
    "print(f\"Orginal dataset\\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e85c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean html tags\n",
    "def clean_html(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r\"<.*?>\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac487225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remoing empty comments\n",
      "                  listing_id                   id        date  reviewer_id  \\\n",
      "0                    164448               407660  2011-07-30       870312   \n",
      "1                    164448               451097  2011-08-16       901633   \n",
      "2                    164448               472271  2011-08-24       894674   \n",
      "3                    164448               521708  2011-09-11       232485   \n",
      "4                    164448               568347  2011-09-26       896712   \n",
      "...                     ...                  ...         ...          ...   \n",
      "144943  1305729897949100039  1317299844322463966  2024-12-22    666963478   \n",
      "144944  1306393577432561110  1315873156254706149  2024-12-20    442177472   \n",
      "144945  1310885179474906446  1316587888366107935  2024-12-21     53058534   \n",
      "144946  1312171107579620356  1320280905319488958  2024-12-26    595482193   \n",
      "144947  1316786620019656619  1322401494741586698  2024-12-29    135251598   \n",
      "\n",
      "       reviewer_name                                           comments  \n",
      "0               Fred  great fun at lidia's. she had the power adapte...  \n",
      "1             Julien  Great centrally located room, very nice facili...  \n",
      "2            Liliana  Lidia is a very nice person. Very good plase t...  \n",
      "3               Ravi  Great host, although we were late in our arriv...  \n",
      "4               Ruud  Good location (for us), the bed was good and t...  \n",
      "...              ...                                                ...  \n",
      "144943        Jurgen  mooi appartement op de perfecte ligging in de ...  \n",
      "144944          Alex  Had a great stay at Jairo’s flat! The room its...  \n",
      "144945        Danish  Tunnelbanan går precis utanför, så det är enke...  \n",
      "144946       Abdulla  lägenheten är inte renoverad på väldigt lång t...  \n",
      "144947          Olle  Fantastisk värd, perfekt läge på boendet! Läge...  \n",
      "\n",
      "[144934 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove the empty comments rows\n",
    "df = df.dropna(subset=[\"comments\"])\n",
    "df[\"comments\"] = df[\"comments\"].apply(clean_html)\n",
    "print(f\"After remoing empty comments\\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76802794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing non-english comments\n",
      "                  listing_id                   id        date  reviewer_id  \\\n",
      "0                    164448               407660  2011-07-30       870312   \n",
      "1                    164448               451097  2011-08-16       901633   \n",
      "2                    164448               472271  2011-08-24       894674   \n",
      "3                    164448               521708  2011-09-11       232485   \n",
      "4                    164448               568347  2011-09-26       896712   \n",
      "...                     ...                  ...         ...          ...   \n",
      "144934  1298010749055182234  1312307766873062259  2024-12-15    436029491   \n",
      "144935  1298347645930946959  1307248295819579395  2024-12-08    479920506   \n",
      "144938  1301950247646962698  1316668854181848371  2024-12-21     34223838   \n",
      "144942  1304284803854492401  1307949554237811713  2024-12-09     86342696   \n",
      "144944  1306393577432561110  1315873156254706149  2024-12-20    442177472   \n",
      "\n",
      "       reviewer_name                                           comments  \\\n",
      "0               Fred  great fun at lidia's. she had the power adapte...   \n",
      "1             Julien  Great centrally located room, very nice facili...   \n",
      "2            Liliana  Lidia is a very nice person. Very good plase t...   \n",
      "3               Ravi  Great host, although we were late in our arriv...   \n",
      "4               Ruud  Good location (for us), the bed was good and t...   \n",
      "...              ...                                                ...   \n",
      "144934       Austėja  Everything was good. The owner was really frie...   \n",
      "144935      Mercedes  Oskar was great with his communication and alw...   \n",
      "144938          Lars  Erica’s apartment was perfect for us. It has e...   \n",
      "144942         Tessa  A really lovely apartment with lots of charact...   \n",
      "144944          Alex  Had a great stay at Jairo’s flat! The room its...   \n",
      "\n",
      "        is_english  \n",
      "0             True  \n",
      "1             True  \n",
      "2             True  \n",
      "3             True  \n",
      "4             True  \n",
      "...            ...  \n",
      "144934        True  \n",
      "144935        True  \n",
      "144938        True  \n",
      "144942        True  \n",
      "144944        True  \n",
      "\n",
      "[99706 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter out the rows that isn't in English\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "df[\"is_english\"] = df[\"comments\"].apply(is_english)\n",
    "df = df[df[\"is_english\"]]\n",
    "print(f\"After removing non-english comments\\n {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40565f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained BERT model for sentiment analysis...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pre-trained BERT model for sentiment analysis...\")\n",
    "# load a pre-trained bert model from tensorflow hub\n",
    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76be1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "\n",
    "def build_classifier_model():\n",
    "    hub_layer = hub.KerasLayer(model_url, trainable=False)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        hub_layer,\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labels for training model...\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "print(\"Creating labels for training model...\")\n",
    "positive_words = ['great', 'good', 'nice', 'excellent', 'perfect', 'happy', 'wonderful', \n",
    "                 'fantastic', 'amazing', 'love', 'best', 'beautiful', 'clean', 'comfortable']\n",
    "negative_words = ['bad', 'poor', 'terrible', 'horrible', 'awful', 'worst', 'dirty', \n",
    "                 'disappointing', 'disappointment', 'uncomfortable', 'problem', 'not clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0368d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sentiment(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 1\n",
    "    \n",
    "    text = text.lower()\n",
    "    pos_count = sum(1 for word in positive_words if word in text)\n",
    "    neg_count = sum(1 for word in negative_words if word in text)\n",
    "\n",
    "    if neg_count > pos_count:\n",
    "        return 0 # negative\n",
    "    else:\n",
    "        return 1 # Default to positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f8847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple labels\n",
    "df[\"sentiment_label\"] = df[\"comments\"].apply(simple_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial sentiment distribution:\n",
      "sentiment_label\n",
      "1    99320\n",
      "0      386\n",
      "Name: count, dtype: int64\n",
      "Positive percentage: 99.61%\n"
     ]
    }
   ],
   "source": [
    "# Print distribution of initial labels\n",
    "print(\"\\nInitial sentiment distribution:\")\n",
    "label_counts = df[\"sentiment_label\"].value_counts()\n",
    "print(label_counts)\n",
    "print(f\"Positive percentage: {label_counts[1]/len(df)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample subset for training\n",
    "sample_size = min(10000, len(df))\n",
    "sample_df = df.sample(sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6804f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text data...\n"
     ]
    }
   ],
   "source": [
    "# text preprocessing\n",
    "print(f\"Preprocessing text data...\")\n",
    "max_features = 10000\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a216032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(sample_df[\"comments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text to sequences\n",
    "x_sequences = tokenizer.texts_to_sequences(sample_df[\"comments\"])\n",
    "x_padded = pad_sequences(x_sequences, maxlen=max_length)\n",
    "y = sample_df[\"sentiment_label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a90187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8000, 200)\n",
      "Validation data shape: (2000, 200)\n"
     ]
    }
   ],
   "source": [
    "# split into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_padded, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Validation data shape: {x_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e29cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and training sentiment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# build a simple neural network model\n",
    "print(\"Building and training sentiment model...\")\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_features, 128, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalMaxPool1D(),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bea9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7032fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb24096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "True\n",
      "True\n",
      "WARNING:tensorflow:From /tmp/ipykernel_28069/2033974726.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_28069/2033974726.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745488941.578492   28069 gpu_device.cc:2019] Created device /device:GPU:0 with 6687 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:2b:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())  # Check if TensorFlow is built with CUDA\n",
    "print(tf.test.is_built_with_gpu_support())  # Check if GPU support is enabled\n",
    "print(tf.test.is_gpu_available())  # Check if GPU is available and usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745489013.764935   29330 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "E0000 00:00:1745489013.811076   29330 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-04-24 12:03:33.814901: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_28069/2429203810.py\", line 2, in <module>\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_9410]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_28069/2429203810.py\", line 2, in <module>\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/mnt/c/pa2572/assignment_1/pa2572/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_9410]"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
